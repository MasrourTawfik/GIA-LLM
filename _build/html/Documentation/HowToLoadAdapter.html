<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>How to Load an Adapter and Attach It to the Model &mdash; ChatG2IA  documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=5929fcd5"></script>
        <script src="../_static/doctools.js?v=888ff710"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            ChatG2IA
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <!-- Local TOC -->
              <div class="local-toc"><ul>
<li><a class="reference internal" href="#">How to Load an Adapter and Attach It to the Model</a><ul>
<li><a class="reference internal" href="#install-required-packages">1. Install Required Packages</a></li>
<li><a class="reference internal" href="#load-and-configure-the-model">2. Load and Configure the Model</a></li>
<li><a class="reference internal" href="#load-adapters-with-peft">3. Load adapters with ü§ó PEFT</a><ul>
<li><a class="reference internal" href="#enable-and-disable-the-adapter">Enable and Disable the Adapter</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">ChatG2IA</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">How to Load an Adapter and Attach It to the Model</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/Documentation/HowToLoadAdapter.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="how-to-load-an-adapter-and-attach-it-to-the-model">
<h1>How to Load an Adapter and Attach It to the Model<a class="headerlink" href="#how-to-load-an-adapter-and-attach-it-to-the-model" title="Link to this heading">ÔÉÅ</a></h1>
<p>To enhance the capabilities of your model, you can load pre-trained <code class="docutils literal notranslate"><span class="pre">adapters</span></code> and attach them. This process involves loading the adapter, previously pushed to the Hugging Face Model Hub, and then attaching it to your existing model. Follow these steps to achieve this integration:</p>
<section id="install-required-packages">
<h2>1. Install Required Packages<a class="headerlink" href="#install-required-packages" title="Link to this heading">ÔÉÅ</a></h2>
<p>Before proceeding, make sure to install the necessary Python packages. Open your terminal, command prompt, or a code cell in your preferred environment (e.g., Jupyter Notebook, Google Colab) and run the following commands:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>!pip<span class="w"> </span>install<span class="w"> </span>peft
!pip<span class="w"> </span>install<span class="w"> </span>bitsandbytes
!pip<span class="w"> </span>install<span class="w"> </span>transformers
!pip<span class="w"> </span>install<span class="w"> </span>accelerate
</pre></div>
</div>
<p>This ensures that you have the required dependencies installed.</p>
</section>
<section id="load-and-configure-the-model">
<h2>2. Load and Configure the Model<a class="headerlink" href="#load-and-configure-the-model" title="Link to this heading">ÔÉÅ</a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Before loading the adapter, ensure the model is loaded. If it‚Äôs already loaded, proceed to the next stage. If not, execute the following Python code:</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">bitsandbytes</span> <span class="k">as</span> <span class="nn">bnb</span>
<span class="kn">import</span> <span class="nn">transformers</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="kn">from</span> <span class="nn">peft</span> <span class="kn">import</span> <span class="p">(</span>
<span class="n">LoraConfig</span><span class="p">,</span>
<span class="n">PeftConfig</span><span class="p">,</span>
<span class="n">PeftModel</span><span class="p">,</span>
<span class="n">get_peft_model</span><span class="p">,</span>
<span class="n">prepare_model_for_kbit_training</span>
<span class="p">)</span>

<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="p">(</span>
<span class="n">AutoConfig</span><span class="p">,</span>
<span class="n">AutoModelForCausalLM</span><span class="p">,</span>
<span class="n">AutoTokenizer</span><span class="p">,</span>
<span class="n">BitsAndBytesConfig</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;alexsherstinsky/Mistral-7B-v0.1-sharded&quot;</span> <span class="c1"># This model is just an example. You can use any model you want from the Hugging Face Model Hub.</span>

<span class="n">bnb_config</span> <span class="o">=</span> <span class="n">BitsAndBytesConfig</span><span class="p">(</span>
      <span class="n">load_in_4bit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
      <span class="n">bnb_4bit_use_double_quant</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
      <span class="n">bnb_4bit_quant_type</span><span class="o">=</span><span class="s2">&quot;nf4&quot;</span><span class="p">,</span>
      <span class="n">bnb_4bit_compute_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
      <span class="n">model_name</span><span class="p">,</span>
      <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
      <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
      <span class="n">quantization_config</span><span class="o">=</span><span class="n">bnb_config</span>
<span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
<span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>
</pre></div>
</div>
<p>The following code defines a prompt generating a response based on a given instruction and input. (It‚Äôs just an example).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">instruction</span> <span class="o">=</span> <span class="s2">&quot;Create a function to calculate the sum of a sequence of integers.&quot;</span>
<span class="nb">input</span> <span class="o">=</span> <span class="s2">&quot;[1, 2, 3, 4, 5]&quot;</span>

<span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;Below is an instruction that describes a task. Write a response that appropriately completes the request.</span>
<span class="s2">### Instruction: </span><span class="si">{</span><span class="n">instruction</span><span class="si">}</span>
<span class="s2">### Input: </span><span class="si">{</span><span class="nb">input</span><span class="si">}</span>
<span class="s2">### Response:</span>
<span class="s2">&quot;&quot;&quot;</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">encodeds</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span> <span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">model_inputs</span> <span class="o">=</span> <span class="n">encodeds</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="load-adapters-with-peft">
<h2>3. Load adapters with ü§ó PEFT<a class="headerlink" href="#load-adapters-with-peft" title="Link to this heading">ÔÉÅ</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">Parameter-Efficient</span> <span class="pre">Fine</span> <span class="pre">Tuning</span> <span class="pre">(PEFT)</span></code> methods freeze the pretrained model parameters during fine-tuning and add a small number of trainable parameters (the adapters) on top of it. The adapters are trained to learn task-specific information.</p>
<p>To load and use a PEFT adapter model from ü§ó Transformers, make sure the Hub repository or local directory contains an adapter_config.json file and the adapter weights, as shown in the example image above.</p>
<img alt="Adapter config file and weights" class="align-center" src="../_images/peft.JPG" />
<div class="line-block">
<div class="line"><br /></div>
</div>
<p>Then you can load the PEFT adapter model using the code below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">peft_model_id</span> <span class="o">=</span> <span class="s2">&quot;FatimaZahra25/Zephyr_beta&quot;</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_adapter</span><span class="p">(</span><span class="n">peft_model_id</span><span class="p">)</span>
</pre></div>
</div>
<section id="enable-and-disable-the-adapter">
<h3>Enable and Disable the Adapter<a class="headerlink" href="#enable-and-disable-the-adapter" title="Link to this heading">ÔÉÅ</a></h3>
<p>Once you‚Äôve added an adapter to a model, you can enable or disable the adapter module. To enable the adapter module:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">enable_adapters</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">generated_ids</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="o">**</span><span class="n">model_inputs</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">do_sample</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">decoded</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">generated_ids</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">decoded</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
<p>To disable the adapter module:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">disable_adapters</span><span class="p">()</span>
</pre></div>
</div>
<div class="admonition attention">
<p class="admonition-title">Attention</p>
<p>The adapter functionality currently utilizes GPU memory.</p>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, GIIA.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>