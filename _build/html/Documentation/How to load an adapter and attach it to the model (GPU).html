<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>How to load an adapter and attach it to the model (GPU) &mdash; ChatG2IA  documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=19f00094" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=5929fcd5"></script>
        <script src="../_static/doctools.js?v=888ff710"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="How to load an adapter and attach it to the model" href="How%20to%20load%20an%20adapter%20and%20attach%20it%20to%20the%20model.html" />
    <link rel="prev" title="Pushing the adapter into HuggingFace" href="Pushing%20the%20adapter%20to%20HuggingFace%20repo.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            ChatG2IA
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Table of Content:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="Introduction.html">Introduction</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="Model.html">Model</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="HuggingFace%20base%20model%20interaction.html">HuggingFace base model interaction</a></li>
<li class="toctree-l2"><a class="reference internal" href="Fine-tuning%20using%20hugging%20face%20libraries.html">Fine-tuning using hugging face libraries</a></li>
<li class="toctree-l2"><a class="reference internal" href="Fine-tuning%20using%20Ludwig.html">Fine-tuning using Ludwig</a></li>
<li class="toctree-l2"><a class="reference internal" href="Pushing%20the%20adapter%20to%20HuggingFace%20repo.html">Pushing the adapter into HuggingFace</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">How to load an adapter and attach it to the model (GPU)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#install-required-packages">1. Install Required Packages</a></li>
<li class="toctree-l3"><a class="reference internal" href="#load-and-configure-the-model">2. Load and Configure the Model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#load-adapters-with-peft">3. Load adapters with ü§ó PEFT</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#enable-and-disable-the-adapter">Enable and Disable the Adapter</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="How%20to%20load%20an%20adapter%20and%20attach%20it%20to%20the%20model.html">How to load an adapter and attach it to the model</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="Synthetic_data.html">Synthetic Data</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">ChatG2IA</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="Model.html">Model</a></li>
      <li class="breadcrumb-item active">How to load an adapter and attach it to the model (GPU)</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/Documentation/How to load an adapter and attach it to the model (GPU).rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="how-to-load-an-adapter-and-attach-it-to-the-model-gpu">
<h1>How to load an adapter and attach it to the model (GPU)<a class="headerlink" href="#how-to-load-an-adapter-and-attach-it-to-the-model-gpu" title="Link to this heading">ÔÉÅ</a></h1>
<p class="linemarker linemarker-4">To enhance the capabilities of your model, you can load pre-trained <code class="docutils literal notranslate"><span class="pre">adapters</span></code> and attach them. This process involves loading the adapter, previously pushed to the Hugging Face Model Hub, and then attaching it to your existing model. Follow these steps to achieve this integration:</p>
<section id="install-required-packages">
<h2>1. Install Required Packages<a class="headerlink" href="#install-required-packages" title="Link to this heading">ÔÉÅ</a></h2>
<p class="linemarker linemarker-9">Before proceeding, make sure to install the necessary Python packages. Open your terminal, command prompt, or a code cell in your preferred environment (e.g., Jupyter Notebook, Google Colab) and run the following commands:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>!pip<span class="w"> </span>install<span class="w"> </span>peft
!pip<span class="w"> </span>install<span class="w"> </span>bitsandbytes
!pip<span class="w"> </span>install<span class="w"> </span>transformers
!pip<span class="w"> </span>install<span class="w"> </span>accelerate
</pre></div>
</div>
<p class="linemarker linemarker-18">This ensures that you have the required dependencies installed.</p>
</section>
<section id="load-and-configure-the-model">
<h2>2. Load and Configure the Model<a class="headerlink" href="#load-and-configure-the-model" title="Link to this heading">ÔÉÅ</a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p class="linemarker linemarker-24">Before loading the adapter, ensure the model is loaded. If it‚Äôs already loaded, proceed to the next stage. If not, execute the following Python code:</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">bitsandbytes</span> <span class="k">as</span> <span class="nn">bnb</span>
<span class="kn">import</span> <span class="nn">transformers</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="kn">from</span> <span class="nn">peft</span> <span class="kn">import</span> <span class="p">(</span>
<span class="n">LoraConfig</span><span class="p">,</span>
<span class="n">PeftConfig</span><span class="p">,</span>
<span class="n">PeftModel</span><span class="p">,</span>
<span class="n">get_peft_model</span><span class="p">,</span>
<span class="n">prepare_model_for_kbit_training</span>
<span class="p">)</span>

<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="p">(</span>
<span class="n">AutoConfig</span><span class="p">,</span>
<span class="n">AutoModelForCausalLM</span><span class="p">,</span>
<span class="n">AutoTokenizer</span><span class="p">,</span>
<span class="n">BitsAndBytesConfig</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;alexsherstinsky/Mistral-7B-v0.1-sharded&quot;</span> <span class="c1"># This model is just an example. You can use any model you want from the Hugging Face Model Hub.</span>

<span class="n">bnb_config</span> <span class="o">=</span> <span class="n">BitsAndBytesConfig</span><span class="p">(</span>
      <span class="n">load_in_4bit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
      <span class="n">bnb_4bit_use_double_quant</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
      <span class="n">bnb_4bit_quant_type</span><span class="o">=</span><span class="s2">&quot;nf4&quot;</span><span class="p">,</span>
      <span class="n">bnb_4bit_compute_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
      <span class="n">model_name</span><span class="p">,</span>
      <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
      <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
      <span class="n">quantization_config</span><span class="o">=</span><span class="n">bnb_config</span>
<span class="p">)</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
<span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>
</pre></div>
</div>
<p class="linemarker linemarker-69">The following code defines a prompt generating a response based on a given instruction and input. (It‚Äôs just an example).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">instruction</span> <span class="o">=</span> <span class="s2">&quot;Create a function to calculate the sum of a sequence of integers.&quot;</span>
<span class="nb">input</span> <span class="o">=</span> <span class="s2">&quot;[1, 2, 3, 4, 5]&quot;</span>

<span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;Below is an instruction that describes a task. Write a response that appropriately completes the request.</span>
<span class="s2">### Instruction: </span><span class="si">{</span><span class="n">instruction</span><span class="si">}</span>
<span class="s2">### Input: </span><span class="si">{</span><span class="nb">input</span><span class="si">}</span>
<span class="s2">### Response:</span>
<span class="s2">&quot;&quot;&quot;</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">encodeds</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span> <span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">model_inputs</span> <span class="o">=</span> <span class="n">encodeds</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="load-adapters-with-peft">
<h2>3. Load adapters with ü§ó PEFT<a class="headerlink" href="#load-adapters-with-peft" title="Link to this heading">ÔÉÅ</a></h2>
<p class="linemarker linemarker-90"><code class="docutils literal notranslate"><span class="pre">Parameter-Efficient</span> <span class="pre">Fine</span> <span class="pre">Tuning</span> <span class="pre">(PEFT)</span></code> methods freeze the pretrained model parameters during fine-tuning and add a small number of trainable parameters (the adapters) on top of it. The adapters are trained to learn task-specific information.</p>
<p class="linemarker linemarker-92">To load and use a PEFT adapter model from ü§ó Transformers, make sure the Hub repository or local directory contains an adapter_config.json file and the adapter weights, as shown in the example image above.</p>
<img alt="Adapter config file and weights" class="align-center" src="../_images/peft.JPG" />
<div class="line-block">
<div class="line"><br /></div>
</div>
<p class="linemarker linemarker-100">Then you can load the PEFT adapter model using the code below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">peft_model_id</span> <span class="o">=</span> <span class="s2">&quot;FatimaZahra25/Zephyr_beta&quot;</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_adapter</span><span class="p">(</span><span class="n">peft_model_id</span><span class="p">)</span>
</pre></div>
</div>
<section id="enable-and-disable-the-adapter">
<h3>Enable and Disable the Adapter<a class="headerlink" href="#enable-and-disable-the-adapter" title="Link to this heading">ÔÉÅ</a></h3>
<p class="linemarker linemarker-110">Once you‚Äôve added an adapter to a model, you can enable or disable the adapter module. To enable the adapter module:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">enable_adapters</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">generated_ids</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="o">**</span><span class="n">model_inputs</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">do_sample</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">decoded</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">generated_ids</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">decoded</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
<p class="linemarker linemarker-122">To disable the adapter module:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">disable_adapters</span><span class="p">()</span>
</pre></div>
</div>
<div class="admonition attention">
<p class="admonition-title">Attention</p>
<p class="linemarker linemarker-129">The adapter functionality currently utilizes GPU memory.</p>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="Pushing%20the%20adapter%20to%20HuggingFace%20repo.html" class="btn btn-neutral float-left" title="Pushing the adapter into HuggingFace" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="How%20to%20load%20an%20adapter%20and%20attach%20it%20to%20the%20model.html" class="btn btn-neutral float-right" title="How to load an adapter and attach it to the model" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, GIIA.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>