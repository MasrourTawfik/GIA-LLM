Search.setIndex({"docnames": ["Documentation/Chainlit", "Documentation/Customization", "Documentation/Fine-tuning using Ludwig", "Documentation/Fine-tuning using hugging face libraries", "Documentation/GPT4", "Documentation/How to load an adapter and attach it to the model", "Documentation/How to load an adapter and attach it to the model (GPU)", "Documentation/How to load data based on an adapter fine-tuned on a sample of synthetic data generated by GPT-4", "Documentation/HuggingFace base model interaction", "Documentation/Introduction", "Documentation/Model", "Documentation/Pushing the adapter to HuggingFace repo", "Documentation/Setup", "Documentation/Synthetic_data", "index"], "filenames": ["Documentation/Chainlit.rst", "Documentation/Customization.rst", "Documentation/Fine-tuning using Ludwig.rst", "Documentation/Fine-tuning using hugging face libraries.rst", "Documentation/GPT4.rst", "Documentation/How to load an adapter and attach it to the model.rst", "Documentation/How to load an adapter and attach it to the model (GPU).rst", "Documentation/How to load data based on an adapter fine-tuned on a sample of synthetic data generated by GPT-4.rst", "Documentation/HuggingFace base model interaction.rst", "Documentation/Introduction.rst", "Documentation/Model.rst", "Documentation/Pushing the adapter to HuggingFace repo.rst", "Documentation/Setup.rst", "Documentation/Synthetic_data.rst", "index.rst"], "titles": ["Chainlit", "Customization", "Fine-tuning using Ludwig", "Fine-tuning using hugging face libraries", "GPT4", "How to load an adapter and attach it to the model", "How to load an adapter and attach it to the model (GPU)", "How to load data based on an adapter fine-tuned on a sample of synthetic data generated by GPT-4", "HuggingFace base model interaction", "Introduction", "Model", "Pushing the adapter into HuggingFace", "Setup", "Synthetic Data", "Welcome to Chat2IA\u2019s documentation!"], "terms": {"index": [2, 14], "modul": [6, 14], "search": 14, "page": [11, 14], "h": [], "toctre": [], "maxdepth": [], "2": [10, 11, 13], "caption": [], "content": 11, "he": 2, "hel": [], "hell": [], "hello": [], "w": [], "wo": [], "wor": [], "worl": [], "world": 2, "o": 2, "ok": [], "oka": [], "okasa": [], "okasasa": [], "yooooooo": [], "l": [], "lo": [], "loa": [], "load": [2, 3, 10, 13, 14], "ad": 6, "ada": [], "adap": [], "adapt": [2, 10, 13, 14], "i": [2, 6, 11, 12], "In": 11, "t": [], "th": [], "thi": [2, 6, 11, 12], "": [6, 10], "se": [], "sec": [], "sect": [], "secti": [], "sectio": [], "section": 11, "we": [2, 11], "show": 11, "you": [3, 6, 11, 12], "how": [2, 10, 11, 13, 14], "your": [3, 6, 10, 11], "allow": [2, 11], "us": [6, 10, 11, 12, 14], "ecosystem": [], "e": [6, 12], "g": [6, 12], "hub": [6, 11], "http": 2, "adapterhub": [], "ml": [], "ea": [], "easi": [], "easil": [], "easili": 11, "ac": [], "acc": [], "access": [2, 11, 12], "y": 2, "yo": [], "from": [2, 3, 6, 11, 12], "own": 11, "project": [11, 12], "n": 2, "note": [], "assum": 11, "have": [2, 6, 11, 12], "alreadi": [6, 11], "creat": [2, 3, 6, 11, 12], "an": [2, 10, 11, 13, 14], "account": 11, "If": [6, 11], "done": 11, "so": 11, "pleas": 11, "refer": [11, 12], "adapter_cr": [], "first": 11, "f": 6, "fo": [], "fol": [], "foll": [], "follo": [], "follow": [2, 3, 6, 11, 12], "wen": [], "went": 11, "thr": [], "thro": [], "throu": [], "throug": [], "through": [11, 12], "fi": [], "fin": [], "fine": [6, 10, 11, 13, 14], "tu": [], "tun": [], "tuni": [], "tunin": [], "tune": [6, 10, 11, 13, 14], "u": [], "usi": [], "usin": [], "lu": [], "lud": [], "ludw": [], "ludwi": [], "ludwig": [10, 14], "li": [], "lib": [], "libr": [], "libra": [], "librar": [], "librari": [10, 11, 14], "go": [2, 11], "b": [], "ba": [], "bac": [], "back": 11, "fir": [], "3": [10, 11, 13], "tui": [], "c": [], "co": [], "cod": [], "code": [6, 10], "The": [6, 10, 12], "step": [3, 6, 12], "import": [6, 10], "model": [2, 3, 11, 14], "want": [2, 6, 11], "exampl": [2, 6, 11], "previou": [], "ins": [], "inst": [], "insta": [], "instal": [10, 13], "ludi": [], "A": [], "As": [], "ass": [], "assu": [], "assumi": [], "assumin": [], "tha": [], "ha": [], "hav": [], "our": [], "can": [2, 3, 6, 12], "now": [2, 11], "To": [2, 3, 6, 11, 12], "do": [2, 11], "contrib": [], "huggingfac": [10, 14], "contain": 6, "singl": 2, "function": 6, "push_to_hub": [], "which": [], "take": [], "input": [2, 6], "path": [], "directori": 6, "name": [2, 11], "return": 2, "url": [], "ll": [], "llm": [10, 11, 12], "op": [], "open": [6, 11], "sou": [], "sour": [], "sourc": 11, "ch": [], "cho": [], "choi": [], "choic": 11, "At": 11, "en": [], "end": 11, "tr": [], "tra": [], "trai": [], "traii": [], "traiin": [], "train": [2, 3, 6, 11], "traini": [], "trainin": [], "ge": [], "get": [], "ne": [], "new": [2, 11], "folder": 11, "result": [2, 11], "file": [6, 12], "thisi": [], "wh": [], "wha": [], "what": 11, "wi": [], "wil": [], "see": [2, 11], "af": [], "aft": [], "after": 11, "com": 2, "comp": [], "compl": [], "complet": [2, 6, 12], "d": [], "don": [], "config": [2, 11, 12], "yaml": [2, 11], "pytorch_model": 11, "bin": 11, "special_tokens_map": 11, "json": [6, 11], "tokenizer_config": 11, "training_arg": 11, "vocab": 11, "log": [2, 11], "training_result": 11, "llm_adapt": 11, "pytorch_adapt": 11, "ap": [], "api_": [], "api_ex": [], "api_exp": [], "api_experi": [], "api_experiment_": [], "api_experiment_r": [], "api_experiment_ru": [], "api_experiment_run": 11, "api_experiment_run_": [], "api_experiment_run_3": [], "api_experiment_run_x": 11, "experi": [], "x": 11, "run": [6, 11, 12], "integ": [6, 11], "ca": [], "cal": [], "call": [2, 11], "ex": [], "exa": [], "exam": [], "examp": [], "No": [], "p": [], "pu": [], "need": 11, "command": [6, 11], "upload": 11, "hf_hub": 11, "repo_id": 11, "imadsaddik": [], "mistral_7b_python_code_instructions_18k_alpaca": [], "model_path": 11, "push_adapt": [], "adapter_path": [], "model_name_or_path": [], "adapter_nam": [], "adapter_typ": [], "tokenizer_name_or_path": [], "pr": [], "pro": [], "prof": [], "profi": [], "profil": 11, "r": [], "re": 2, "rep": [], "repo": [], "repo_": [], "repo_n": [], "repo_na": [], "repo_nam": 11, "ab": [], "abl": 11, "environ": [2, 6, 12], "variabl": [], "set": [2, 3, 12], "cr": [], "cre": [], "crea": [], "token": [3, 6, 10, 11], "click": 11, "button": 11, "Then": [6, 11], "copi": [2, 11], "past": 11, "abov": [2, 6], "oken": [], "cl": [], "cli": [], "clic": [], "toe": [], "toek": [], "tok": [], "toke": [], "bu": [], "butt": [], "butto": [], "gene": [], "gener": [6, 10, 11, 13, 14], "genera": [], "generat": [], "con": [], "conso": [], "consol": 11, "ru": [], "runn": [], "runni": [], "runnin": [], "cm": [], "cmm": [], "cmma": [], "cmman": [], "comm": [], "comma": [], "comman": [], "repo_i": [], "ref": [], "refe": [], "repositori": [6, 11, 12], "For": [11, 12], "usernam": [], "repositoryimadsaddik": [], "azulian": 11, "doctorllm2": 11, "enhanc": 6, "capabl": 6, "pre": [2, 3, 6], "them": 6, "process": [2, 3, 6], "involv": [2, 6], "previous": 6, "push": [6, 10, 14], "hug": [6, 10, 11, 14], "face": [6, 10, 11, 14], "exist": 6, "achiev": 6, "integr": 6, "befor": [6, 12], "proceed": [6, 12], "make": [2, 6], "sure": 6, "necessari": 6, "python": [6, 12], "packag": 10, "termin": 6, "prompt": [2, 6], "cell": 6, "prefer": 6, "jupyt": 6, "notebook": 6, "googl": [2, 6], "colab": [2, 6], "pip": [2, 6, 12], "peft": [2, 10], "bitsandbyt": 6, "transform": [2, 6], "acceler": 6, "ensur": [2, 6, 12], "requir": [2, 3, 10, 12], "depend": [6, 10, 12], "proce": 6, "next": 6, "stage": 6, "execut": 6, "bnb": 6, "torch": [2, 6], "loraconfig": 6, "peftconfig": 6, "peftmodel": 6, "get_peft_model": 6, "prepare_model_for_kbit_train": 6, "autoconfig": 6, "automodelforcausallm": 6, "autotoken": [2, 6], "bitsandbytesconfig": 6, "model_nam": 6, "alexsherstinski": 6, "mistral": 6, "7b": [2, 6], "v0": 6, "shard": 6, "bnb_config": 6, "load_in_4bit": 6, "true": 6, "bnb_4bit_use_double_qu": 6, "bnb_4bit_quant_typ": 6, "nf4": 6, "bnb_4bit_compute_dtyp": 6, "bfloat16": 6, "just": 6, "ani": 6, "from_pretrain": [2, 3, 6], "device_map": 6, "auto": 6, "trust_remote_cod": 6, "quantization_config": 6, "pad_token": 6, "eos_token": 6, "provid": [2, 3, 12], "defin": [3, 6], "respons": [2, 6], "base": [2, 6, 10, 13, 14], "given": 6, "instruct": [2, 6, 12], "calcul": [2, 6], "sum": 6, "sequenc": 6, "4": [6, 10, 13, 14], "5": [2, 6], "below": [2, 6], "describ": [2, 6], "task": [2, 6], "write": [2, 6], "appropri": [2, 6, 12], "request": [2, 6], "encod": 6, "return_tensor": 6, "pt": 6, "add_special_token": 6, "fals": 6, "model_input": 6, "cuda": [2, 6], "queri": [], "string": [], "paramet": [3, 6, 10], "effici": [3, 6, 10], "method": [2, 3, 6], "freez": [2, 6], "pretrain": 6, "dure": [3, 6], "add": [2, 6], "small": [2, 6], "number": [2, 6], "trainabl": 6, "top": 6, "ar": [2, 6], "learn": [2, 6], "specif": [2, 6], "inform": 6, "local": [2, 6], "adapter_config": 6, "weight": [2, 6], "shown": 6, "imag": 6, "br": [], "nbsp": [], "peft_model_id": 6, "fatimazahra25": 6, "zephyr_beta": 6, "load_adapt": 6, "onc": [6, 12], "ve": 6, "enable_adapt": 6, "generated_id": 6, "max_new_token": [2, 6], "1000": 6, "do_sampl": 6, "decod": 6, "batch_decod": 6, "print": 6, "0": [2, 6], "disable_adapt": 6, "current": 6, "util": 6, "gpu": [2, 10, 14], "memori": [2, 6], "updat": [2, 3, 12], "lead": 2, "perform": [2, 3], "improv": 2, "It": [2, 6], "mean": 2, "person": 2, "special": 2, "applic": 2, "optim": 2, "uniqu": 2, "all": 2, "proven": 2, "resourc": 2, "intens": 2, "time": 2, "consum": 2, "alwai": 2, "yield": 2, "howev": 2, "recent": 2, "innov": 2, "offer": 2, "breakthrough": 2, "By": 2, "onli": 2, "veri": 2, "layer": 2, "less": 2, "than": 2, "total": 2, "prove": 2, "both": 2, "friendli": 2, "more": [2, 12], "effect": 2, "declar": 2, "approach": 2, "machin": 2, "interfac": 2, "control": 2, "custom": [2, 13, 14], "without": 2, "extens": 2, "Its": 2, "configur": [2, 10, 13], "empow": 2, "user": 2, "manag": 2, "differ": 2, "featur": 2, "output": 2, "toolkit": 2, "contrain": 2, "includ": 2, "lora": 2, "bit": 2, "quantiz": 2, "let": 2, "delv": 2, "deeper": 2, "nitti": 2, "gritti": 2, "advanc": 2, "uninstal": 2, "tensorflow": 2, "quiet": 2, "ipython": 2, "displai": 2, "html": 2, "def": 2, "set_css": 2, "style": 2, "white": 2, "space": 2, "wrap": 2, "get_ipython": 2, "event": 2, "regist": 2, "pre_run_cel": 2, "clear_cach": 2, "is_avail": 2, "empty_cach": 2, "data_t": 2, "enable_dataframe_formatt": 2, "numpi": 2, "np": 2, "random": 2, "seed": 2, "123": 2, "panda": 2, "pd": 2, "df": 2, "to_panda": 2, "column": 2, "split": 2, "where": 2, "90": 2, "assign": 2, "valu": [2, 12], "valid": [2, 3], "test": [2, 3], "row": 2, "each": 2, "total_row": 2, "len": 2, "split_0_count": 2, "int": 2, "9": 2, "split_1_count": 2, "05": 2, "split_2_count": 2, "arrai": 2, "count": 2, "split_valu": 2, "concaten": 2, "zero": 2, "ones": 2, "full": [2, 12], "shuffl": 2, "datafram": 2, "astyp": 2, "n_row": 2, "5000": 2, "head": 2, "understand": 2, "alpaca": 2, "10": 2, "look": 2, "like": 2, "document": 12, "data": [3, 14], "jpg": [], "width": [], "100": [], "align": [], "center": [], "meant": 2, "larg": 2, "languag": 2, "produc": 2, "natur": 2, "consist": 2, "when": 2, "addit": 2, "context": 2, "expect": 2, "script": 2, "variou": 2, "statist": 2, "distribut": 2, "calculate_distribut": 2, "data_dict": 2, "kei": 2, "item": 2, "averag": 2, "min": 2, "max": 2, "median": 2, "75th_percentil": 2, "percentil": 2, "75": 2, "90th_percentil": 2, "95th_percentil": 2, "95": 2, "99th_percentil": 2, "99": 2, "huggingfaceh4": 2, "zephyr": 2, "beta": 2, "token_count": 2, "iterrow": 2, "instruction_col_token": 2, "input_col_token": 2, "output_col_token": 2, "append": 2, "token_distribut": 2, "upgrad": 2, "git": 2, "github": [2, 12], "getpass": 2, "getpreferredencod": 2, "lambda": 2, "utf": 2, "8": 2, "api": [2, 10], "ludwigmodel": 2, "hugging_face_hub_token": 2, "hf_pqfaqdjhokftuzlfsxiqburbkzityjoru": 2, "assert": 2, "t4": 2, "16gib": 2, "vram": 2, "introduc": 2, "int4": 2, "int8": 2, "reduc": 2, "overhead": 2, "trainer": 2, "enabl": 2, "finetun": 2, "varieti": 2, "epoch": 2, "rate": 2, "imagin": 2, "feed": 2, "pair": 2, "magic": 2, "happen": 2, "act": 2, "guid": 2, "steer": 2, "hand": 2, "And": 2, "come": 2, "plai": 2, "qlora_fine_tuning_config": 2, "safe_load": 2, "model_typ": 2, "reshard": 2, "here": 2, "sinc": 2, "doe": 2, "safetensor": 2, "support": 2, "base_model": 2, "input_featur": 2, "type": 2, "text": 2, "output_featur": 2, "templat": 2, "mai": 2, "further": [2, 3], "temperatur": 2, "256": 2, "preprocess": [2, 3], "global_max_sequence_length": 2, "probabl": 2, "val": 2, "batch_siz": 2, "eval_batch_s": 2, "gradient_accumulation_step": 2, "16": 2, "learning_r": 2, "0004": 2, "learning_rate_schedul": 2, "warmup_fract": 2, "03": 2, "logging_level": 2, "info": 2, "infer": [2, 3], "predict": 2, "some": 2, "whether": 2, "its": 2, "abil": 2, "ask": 2, "iloc": 2, "shape": 2, "test_df": 2, "20": 2, "result_df": 2, "generated_output": 2, "output_respons": 2, "perfect": 2, "especi": 2, "limit": 2, "tweak": 2, "maximum": 2, "etc": 2, "alter": 2, "therebi": 2, "refin": 2, "export": [], "downstream": [], "product": [], "directli": [], "via": [], "prepar": 3, "convert": 3, "format": 3, "loader": 3, "loop": 3, "iter": 3, "over": 3, "evalu": 3, "save": 3, "futur": 3, "interact": [10, 14], "goal": [10, 14], "hf": [10, 14], "1": [10, 13], "tradit": 10, "v": 10, "relat": 10, "dataset": 10, "setup": [10, 13, 14], "artifact": [], "attach": [10, 14], "up": 12, "gia": 12, "7": 12, "higher": 12, "virtual": 12, "virtualenv": 12, "conda": 12, "clone": 12, "activ": 12, "databas": 12, "migrat": 12, "start": 12, "develop": 12, "server": 12, "certain": 12, "locat": 12, "py": 12, "web": 12, "browser": 12, "detail": 12, "avail": 12, "doc": 12, "md": 12, "gpt4": [13, 14], "sampl": [13, 14], "gpt": [13, 14], "chainlit": [13, 14], "prerequisit": 13, "usag": 13, "introduct": 14, "synthet": 14}, "objects": {}, "objtypes": {}, "objnames": {}, "titleterms": {"welcom": 14, "chatg2ia": [], "": [2, 14], "document": 14, "indic": 14, "tabl": 14, "chat2ia": 14, "load": [5, 6, 7], "adapt": [5, 6, 7, 11], "django": [], "channel": [], "l": [], "lo": [], "loa": [], "ad": [], "ada": [], "adap": [], "w": [], "p": [], "pe": [], "pef": [], "peft": 6, "pu": [], "pushi": [], "pushig": [], "pushin": [], "push": 11, "t": [], "th": [], "h": [], "hu": [], "hug": 3, "hugg": [], "huggi": [], "huggin": [], "huggingf": [], "huggingfa": [], "huggingfac": [2, 8, 11], "face": 3, "code": 2, "lu": [], "lud": [], "ludw": [], "ludwi": [], "ludwig": [2, 11], "ap": [], "api": 11, "A": [], "how": [5, 6, 7], "an": [5, 6, 7, 8], "attach": [5, 6], "It": [], "model": [5, 6, 8, 10], "1": [2, 6, 12], "instal": [2, 6, 12], "requir": 6, "packag": 6, "configur": [6, 12], "2": [2, 6, 12], "3": [2, 6, 12], "enabl": 6, "disabl": 6, "fine": [2, 3, 7], "tune": [2, 3, 7], "us": [2, 3], "tradit": 2, "v": 2, "paramet": 2, "effici": 2, "llm": 2, "relat": 2, "depend": 2, "import": 2, "The": 2, "gener": [2, 7], "dataset": 2, "setup": [2, 12], "your": 2, "token": 2, "4": [2, 7, 12], "5": [], "upload": [], "train": [], "artifact": [], "To": [], "chainlit": 0, "custom": 1, "librari": 3, "gpt4": 4, "gpu": 6, "data": [7, 13], "base": [7, 8], "sampl": 7, "synthet": [7, 13], "gpt": 7, "interact": 8, "goal": [8, 9], "hf": [8, 9], "option": [8, 9], "section": 8, "thi": 8, "i": 8, "introduct": 9, "prerequisit": 12, "usag": 12, "content": 14}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx": 60}, "alltitles": {"Chainlit": [[0, "chainlit"]], "Customization": [[1, "customization"]], "Fine-tuning using hugging face libraries": [[3, "fine-tuning-using-hugging-face-libraries"]], "GPT4": [[4, "gpt4"]], "How to load an adapter and attach it to the model": [[5, "how-to-load-an-adapter-and-attach-it-to-the-model"]], "How to load data based on an adapter fine-tuned on a sample of synthetic data generated by GPT-4": [[7, "how-to-load-data-based-on-an-adapter-fine-tuned-on-a-sample-of-synthetic-data-generated-by-gpt-4"]], "HuggingFace base model interaction": [[8, "huggingface-base-model-interaction"]], "Goals": [[8, "goals"], [9, "goals"]], "HF": [[8, "hf"], [9, "hf"]], "Optional Section": [[8, "optional-section"]], "This is an optional section.": [[8, "this-is-an-optional-section"], [8, "id1"]], "Introduction": [[9, "introduction"]], "Optional": [[9, "optional"]], "Model": [[10, "model"]], "Setup": [[12, "setup"]], "1. Prerequisites": [[12, "prerequisites"]], "2. Installation": [[12, "installation"]], "3. Configuration": [[12, "configuration"]], "4. Usage": [[12, "usage"]], "Synthetic Data": [[13, "synthetic-data"]], "Welcome to Chat2IA\u2019s documentation!": [[14, "welcome-to-chat2ia-s-documentation"]], "Table of Content:": [[14, null]], "Indices and tables": [[14, "indices-and-tables"]], "How to load an adapter and attach it to the model (GPU)": [[6, "how-to-load-an-adapter-and-attach-it-to-the-model-gpu"]], "1. Install Required Packages": [[6, "install-required-packages"]], "2. Load and Configure the Model": [[6, "load-and-configure-the-model"]], "3. Load adapters with \ud83e\udd17 PEFT": [[6, "load-adapters-with-peft"]], "Enable and Disable the Adapter": [[6, "enable-and-disable-the-adapter"]], "Pushing the adapter into HuggingFace": [[11, "pushing-the-adapter-into-huggingface"]], "Ludwig API": [[11, "ludwig-api"]], "Fine-tuning using Ludwig": [[2, "fine-tuning-using-ludwig"]], "1. Traditional Fine Tuning Vs. Parameter Efficient Fine-Tuning": [[2, "traditional-fine-tuning-vs-parameter-efficient-fine-tuning"]], "1. Fine-tuning using Ludwig": [[2, "id1"]], "1.1 Install Ludwig and Ludwig\u2019s LLM related dependencies": [[2, "install-ludwig-and-ludwig-s-llm-related-dependencies"]], "1.2. Import The Code Generation Dataset": [[2, "import-the-code-generation-dataset"]], "1.3. Setup Your HuggingFace Token \ud83e\udd17": [[2, "setup-your-huggingface-token"]], "1.4. Fine-tuning": [[2, "fine-tuning"]]}, "indexentries": {}})